---
title: "Infra Health Monitoring Suite"
datePublished: Fri Jul 04 2025 11:59:26 GMT+0000 (Coordinated Universal Time)
cuid: cmcorhsvs001p02l73syo5tjp
slug: infra-health-monitoring-suite
cover: https://cdn.hashnode.com/res/hashnode/image/upload/v1752665898031/114c322c-0cf6-4a06-8a1b-cee33d83ed41.png
tags: docker, json, bash, slack, logging, logs, cronjob, production-ready, shell-script, log-rotation, website-health-check-tools

---

---

## Ever wondered how big tech companies ensure their containers stay healthy, websites stay up, logs stay clean, and alerts donâ€™t spam your team - all in an automated, self-healing way?

In the real world, infrastructure monitoring isnâ€™t just about running a few `docker ps` or pinging a website. Itâ€™s about combining smart health checks, meaningful alerts, automated log handling, and real-time status dashboards â€” seamlessly and reliably.

Thatâ€™s exactly why I built this **complete Docker & Website Health Monitoring Suite**, fully written in shell scripting.

The goal?  
ðŸŸ£Automate container and website health checks.  
ðŸŸ£Send intelligent, non-spammy alerts directly to Slack.  
ðŸŸ£Rotate and archive logs before they grow out of control.  
ðŸŸ£ Maintain a JSON-based dashboard for clean visibility.  
ðŸŸ£Schedule it all to run hands-free via cron jobs.  
ðŸŸ£Combine these into one unified, production-ready toolkit you can plug into any system.

Through this project, I got to solve real DevOps challenges, simulate real-world failures, and design a system that feels like a mini in-house monitoring service â€” but with no extra tools, just pure Linux magic.

In this blog, Iâ€™ll break down every piece â€” from container health logic to JSON dashboards â€” in a practical, step-by-step way so you can understand, learn, and build your own.

---

**Now, letâ€™s dive deep into the architecture, folder structure, and scripts behind this monitoring powerhouse.**

# Folder Structure

```txt
docker-health-monitor/
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ container-health.log
â”‚   â””â”€â”€ site-uptime.log
â”œâ”€â”€ archive/
â”‚   â””â”€â”€ rotated-logs/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ services.txt      # list of websites to monitor
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ check_docker_health.sh
â”‚   â”œâ”€â”€ check_website_uptime.sh
â”‚   â”œâ”€â”€ alert.sh
â”‚   â”œâ”€â”€ log_rotate.sh
â”‚   â””â”€â”€ main.sh           # Entry point CLI
â”œâ”€â”€ cron/
â”‚   â””â”€â”€ cronjob.txt       # cron entry for automation
â”œâ”€â”€ README.md
â””â”€â”€ setup.sh              # to setup project (permissions, envs)
```

---

# Create Docker Container With Health Checks

`Without this, container inspect wont produce container status`

```bash
docker run -d \
Â  Â  --name my-nginx \
Â  Â  --health-cmd='curl -f http://localhost:80/ || exit 1' \
Â  Â  --health-interval=30s \
Â  Â  --health-timeout=5s \
Â  Â  --health-retries=3 \
Â  Â  --health-start-period=10s \
Â  Â  nginx
```

#### **Docker exerts an excellent command** `filter='{{.Name}}` -- used to fetch particular things from docker cmds

```bash
docker inspect --format='{{.Name}}' $id | cut -d'/' -f2
docker ps --format='{{.ID}} {{.Name}}'
```

## Creating Container Health Checking Script

```bash
#!/bin/bash
set -e Â # if anything return other than 0 -- exit the script

echo "Checking All Containers Health......"

logs_dir="$(dirname "$0")/../logs" Â # we dont want inside scripts we want in root
log_file="$logs_dir/container-health.log"

mkdir -p "$logs_dir"
  
# Function to fetch name and health check from docker inspect command
fetch_container_status(){
Â  Â  for id in $(docker ps -q); do
Â  Â  Â  Â  name=$(docker inspect --format='{{.Name}}' $id | cut -d'/' -f2)
Â  Â  Â  Â  health=$(docker inspect --format='{{.State.Health.Status}}' $id)
Â  Â  Â  Â  if [ $health == "healthy" ]; then
Â  Â  Â  Â  Â  Â  echo -e "\e[32m$name is healthy\e[0m"
Â  Â  Â  Â  elif [ $health == "starting" ]; then
Â  Â  Â  Â  Â  Â  echo -e "\e[36m$name is starting\e[0m"
Â  Â  Â  Â  elif [ $health == "unhealthy" ]; then
Â  Â  Â  Â  Â  Â  echo -e "\e[31m$name is UNHEALTHY\e[0m"
Â  Â  Â  Â  else
Â  Â  Â  Â  Â  Â  echo -e "\e[33m$name has no health check defined\e[0m]"
Â  Â  Â  Â  fi
Â  Â  done
}

fetch_container_status

# Log output without color codes
log_output=$(fetch_container_status | sed 's/\x1b\[[0-9]*m//g') # x1b is ESC(e)
echo -e "[$(date +"%d-%m-%Y_%H:%M:%S")] Checking Containers Status...\n$log_output\n****************" >> $log_file
```

---

## Creating Website Health Check Script

### Writing Websites inside /config/services.txt

```bash
my_portfolio="daksh-portfolio.cctlds.online"
google="www.google.com"
youtube="www.youtube.com"
```

## check\_website\_[health.sh](http://health.sh)

```bash
#!/bin/bash

website_file_path="$(dirname "$0")/../config"
website_file="$website_file_path/services.txt"

log_file_path="$(dirname "$0")/../logs"
log_file="$log_file_path/website-health.log"

mkdir -p "$log_file_path"

while IFS= read -r line; do Â  Â  # using IFS to read because for loop will break word into pieces
Â  Â  website=$(echo "$line" | cut -d'=' -f2 | sed 's/"//g' | tr -d '\r')
Â  Â  if [ -n "$website" ]; then
Â  Â  Â  Â  status_code=$(curl -Is --max-time 5 "https://$website" | head -n 1 | awk '{print $2}')
Â  Â  Â  Â  if [[ $status_code -eq 200 ]]; then
Â  Â  Â  Â  Â  Â  echo -e "\e[32m$website is UP (HTTP $status_code)\e[0m"
Â  Â  Â  Â  else
Â  Â  Â  Â  Â  Â  echo -e "\e[31m$website is DOWN (HTTP $status_code)\e[0m"
Â  Â  Â  Â  fi

Â  Â  Â  Â  # Sending Text to Log File
Â  Â  Â  Â  {
Â  Â  Â  Â  Â  Â  echo "$(date +"%d-%m-%Y_%H:%M:%S") ---- $website returned HTTP $status_code"
Â  Â  Â  Â  } >> "$log_file"
Â  Â  fi

done < "$website_file"
echo -e "\e[35mWebsite check completed. Logs saved to: $log_file\e[0m"
echo "===========================================" >> "$log_file"
# echo "$website_file" Â # Uncomment for debugging: prints the path to the services.txt file
```

---

## Creating Alert is site is down and sending to slack

### Fetch the Webhook from Slack

### **Create Webhook**

#### For Slack:

1. Go to: [https://api.slack.com/apps](https://api.slack.com/apps)
    
2. Create new app â†’ Add "Incoming Webhooks"
    
3. Enable Webhooks â†’ Create a Webhook URL for your channel
    
4. Copy the webhook URL â€” weâ€™ll store it securely
    

### **Store Webhook URL in Config**

Create a file: `config/webhook.env`

Add: `SLACK_WEBHOOK_URL="`[`https://hooks.slack.com/services/xxxx/yyyy/zzzz`](https://hooks.slack.com/services/xxxx/yyyy/zzzz)`"`

## Building [alert.sh](http://alert.sh) script

```bash
#!/bin/bash

# fetching Slack Webhook URL from ../config/webhook.env
source "$(dirname "$0")/../config/webhook.env"

# We gonna pass this aler.sh script in webhook so passing things through arg
severity="$1" Â  # Expected values: "critical", "warning", "info"
message="$2" Â  Â # message we wanted to send to slack

# payload accepts json format #! \" means " is treated as " not simple text
payload="{
Â  Â  \"text\": \"[$severity] $message\" Â  Â  Â 
}"

# Check if SLACK_WEBHOOK_URL is set and not empty
if [ -z "$SLACK_WEBHOOK_URL" ]; then
Â  Â  echo "Error: SLACK_WEBHOOK_URL is not set. Please check ../config/webhook.env."
Â  Â  exit 1
fi

# Sending payload to slack via curl
# -s=silent -X=HTTP_Method_Specify -H=Content_type
curl -s -X POST -H 'Content-type: application/json' \
Â  Â  --data "$payload" "$SLACK_WEBHOOK_URL"
```

### Add this into website\_uptime\_script

```bash
echo "Triggering alert for $website with status code $status_code"
# Run this script
bash "$(dirname "$0")/alert.sh" "CRITICAL" "Website is DOWN: $website returned HTTP ${status_code:-404}"
```

---

# Only send alert once per X mins per issue --- Avoid spamming channels

If a website stays down for 30 minutes, and your cron runs every 5 minutes â€” youâ€™ll get `6 identical alerts`. `In a game, if a player keeps getting hit, you donâ€™t want to spam "YOU TOOK DAMAGE" every millisecond`

### Approach: "Last Alert Cache"

1ï¸âƒ£ When you send an alert, you **record** that you sent it (e.g., to a small file per website/container).  
2ï¸âƒ£ Before sending a new alert, you **check** if thereâ€™s already a file indicating an active alert.  
3ï¸âƒ£ If yes â†’ **skip sending**.  
4ï¸âƒ£ If service becomes healthy again â†’ **delete the alert flag file**.

```bash
alert_path="$(dirname "$0")/../alert_flags" # Alert Flags Folder Path - which contain flag for down site
flag_file="$alert_path/$(echo "$website" | md5sum | awk '{print $1}').flag"

Â  Â  Â  Â  if [[ $status_code -eq 200 ]]; then
Â  Â  Â  Â  Â  Â  echo -e "\e[32m$website is UP (HTTP $status_code)\e[0m"

Â  Â  Â  Â  Â  Â  # if flag is present, remove it because now website is up
Â  Â  Â  Â  Â  Â  if [ -f "$flag_file" ];then
Â  Â  Â  Â  Â  Â  Â  Â  # echo "Remove the flag"
Â  Â  Â  Â  Â  Â  Â  Â  rm -rf "$flag_file"
Â  Â  Â  Â  Â  Â  fi

Â  Â  Â  Â  else
Â  Â  Â  Â  Â  Â  echo -e "\e[31m$website is DOWN (HTTP ${status_code:-404})\e[0m"

Â  Â  Â  Â  Â  Â  # If Flag exists do nothing and if not -- create and send notif to slack
Â  Â  Â  Â  Â  Â  if [ ! -f "$flag_file" ]; then
Â  Â  Â  Â  Â  Â  Â  Â  # echo "Send Notification to Slack" echo "Create Flag"
Â  Â  Â  Â  Â  Â  Â  Â  touch "$flag_file"
Â  Â  Â  Â  Â  Â  Â  Â  echo -e "\nTriggering alert for $website with status code ${status_code:-404}\n"
Â  Â  Â  Â  Â  Â  Â  Â  # :- means send status code and if it is not present send 404 as status code
Â  Â  Â  Â  Â  Â  Â  Â  bash "$(dirname "$0")/alert.sh" "CRITICAL" "Website is DOWN: $website returned HTTP ${status_code:-404}"
Â  Â  Â  Â  Â  Â  fi
```

---

# **Log Rotation and Archiving**

Prevent logs from growing infinitely large, avoid disk overflow, and keep old logs archived neatly.

> Create an archive\_file if Log\_File Size &gt; (Set Size), then send data to archive folder with timestamp Make a new log file

```bash
#!/bin/bash

log_file_path="$(dirname "$0")/../logs"
log_file="$log_file_path/website-health.log"


time_stamp=$(date +"%d-%m-%Y_%H-%M-%S")

archive_path="$(dirname "$0")/../logs/website-archive-path"
archive_file="$archive_path/"$time_stamp.log""

mkdir -p "$archive_path"

file_size=$(du -k "$log_file" | cut -f1)

# if file size exceeds 15KB, rotate it
if [[ "$file_size" -gt 15 ]]; then
Â  Â  echo "LogFile got above the size limit. Log File Rotated"
Â  Â  mv "$log_file" "$archive_file"
Â  Â  touch "$log_file"
Â  Â  echo "New log file created at: $log_file"
fi

echo "$file_size KB"
```

---

# Adding Cron Job

```bash
crontab -e
```

### Add these scripts as cronjob

```bash
* * * * * /bin/bash /mnt/c/Studies/Linux/docker-health-monitor/scripts/log_rotate.sh
* * * * * /bin/bash /mnt/c/Studies/Linux/docker-health-monitor/scripts/check_website_uptime.sh
```

---

# Sending Heart Beat to slack stating cron job is working

```bash
#!/bin/bash

source "$(dirname "$0")/../config/webhook.env"

message="Heartbeat: All cron jobs are running fine at $(date +"%d-%m-%Y %H:%M:%S")."

payload="{
Â  Â  \"text\": \"$message\"
}"

curl -s -X POST -H 'Content-type: application/json' \
Â  Â  --data "$payload" "$SLACK_WEBHOOK_URL" &> /dev/null
```

---

# Creating JSON Log File

```bash
#!/bin/bash

json_file_path="$(dirname "$0")/../logs/json_logs"
json_file="$json_file_path/logs.json"

mkdir -p "$json_file_path"
if [ ! -f "$json_file" ]; then
Â  Â  touch "$json_file"
fi

name="$1"
status="$2"
http_status="$3"
latency="$4"

# Creating JSON snippet
service_entry="{
Â  Â  \"Name\": \"$name\",
Â  Â  \"Status\": \"$status\",
Â  Â  \"HTTP_Status\": \"$http_status\",
Â  Â  \"Latency\": \"$latency\"
}"

# Check if json_file is not empty - then append and if it is, append {} into mt file
if [ ! -s "$json_file" ]; then
Â  Â  echo "{
Â  Â  Â  Â  \"last_checked\": \"$(date +"%d-%m-%Y %H:%M:%S")\",
Â  Â  Â  Â  \"services\": [
Â  Â  Â  Â  Â  Â  $service_entry
Â  Â  Â  Â  ]
Â  Â  }" > "$json_file"
else
Â  Â  # File is not empty, we need to append new service
Â  Â  # We read old content (excluding last closing brackets)
Â  Â  # Creating a temp json file for doing operations in it
Â  Â  temp_file="$json_file_path/temp.json"
Â  Â  touch "$temp_file"

Â  Â  #! Remove Last 2 lines from the file and send all to temp to append other
Â  Â  head -n -2 "$json_file" > "$temp_file"

Â  Â  # Append New Service
Â  Â  echo ",$service_entry" >> "$temp_file"
Â  Â  echo " Â  Â  Â ]" >> "$temp_file"
Â  Â  echo "}" >> "$temp_file"

Â  Â  # Move the file to $json_file
Â  Â  mv "$temp_file" "$json_file"
fi
```

---

# Adding Dynamic Changing of Date in JSON Log file using SED

```bash
# Changing Or Appending new date using sed into json file
sed -i "s/\"last_checked\":\".*\"/\"last_checked\":\"$(date +"%d-%m-%Y_%H:%M:%S")\"/" "$json_file"
echo "Date Changed"
```

---

# Visualizing Data using JQ with help of json log file

```bash
#!/bin/bash

json_file="$(dirname "$0")/../logs/json_logs/logs.json"

if [ ! -f "$json_file" ]; then
Â  Â  echo "Create JSON File First"
Â  Â  exit 1
fi

last_checked=$(jq -r '.last_checked' "$json_file")
echo -e "\nLast Checked: $last_checked\n"
echo "--- Services Dashboard --\n"

# Storing JSON Objects Items as variables
jq -c '.services[]' "$json_file" | while read -r line; do
Â  Â  name=$(echo "$line" | jq -r '.Name')
Â  Â  status=$(echo "$line" | jq -r '.Status')
Â  Â  http_status=$(echo "$line" | jq -r '.HTTP_Status')
Â  Â  latency=$(echo "$line" | jq -r '.Latency')

echo -e "Name: $name\nStatus: $status\nHTTP Status: $http_status\nLatency: $latency seconds\n---------------------\n"
done
```